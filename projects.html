<html>
	<head>
		<title>Nikhil CG - Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
        <style>
            h5{text-align: left;}
        </style>
	</head>
	<body class="is-preload">

		<!-- Header -->
			<div id="header">

				<div class="top">

					<!-- Logo -->
						<div id="logo">
							<a href="https://nikhilcg26.github.io/" class="image fit"><span class="image avatar48"><img src="images/crop.jpg" alt="" /></span></a>
							<a href="https://nikhilcg26.github.io/"><h1 id="title">Nikhil CG</h1></a>
							<a href="https://nikhilcg26.github.io/"><p>Robotics Engineer</p></a>
						</div>

					<!-- Nav -->
						<nav id="nav">
							<ul>
								<li><a href="https://nikhilcg26.github.io/index.html#top" id="top-link"><span class="icon solid fa-home">Intro</span></a></li>
								<li><a href="https://nikhilcg26.github.io/index.html#about" id="about-link"><span class="icon solid fa-user">About Me</span></a></li>
								<li><a href="https://nikhilcg26.github.io/index.html#education" id="education-link"><span class="icon solid fa-graduation-cap">Education</span></a></li>
								<li><a href="https://nikhilcg26.github.io/index.html#projects" id="projects-link"><span class="icon solid fa-th">Projects</span></a></li>
								<li><a href="https://nikhilcg26.github.io/index.html#work" id="work-link"><span class="icon solid fa-briefcase">Work Experience</span></a></li>
								<li><a href="https://nikhilcg26.github.io/index.html#contact" id="contact-link"><span class="icon solid fa-envelope">Contact</span></a></li>
                                <li><a href="resume/Resume - Nikhil CG.pdf" target="_blank" id="resume-link"><span class="icon solid fa-file">Resume</span></a></li>
							</ul>
						</nav>

				</div>

				<div class="bottom">

					<!-- Social Icons -->
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/nikhilcg/" target="_blank" class="icon brands fa-linkedin"><span class="label">Linkedin</span></a></li>
							<li><a href="https://github.com/NikhilCG26" target="_blank" class="icon brands fa-github"><span class="label">Github</span></a></li>
							<li><a href="mailto:nchinnal@andrew.cmu.edu" target="_blank" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
						</ul>

				</div>

			</div>
            
        <!--Main-->    
        <div id="main">

            <!--Construction Site-->

            <section id="construction" class="three">
                <div class="container">

                    <header>
                        <h2><span style="color:rgb(0, 0, 0)">Construction Site Hazard Detection using Computer Vision</span></h2>
                    </header>

                    <div class="col-4 col-12-mobile">
                        <div class="inner">
                            <article class="item">
                                <div class="row">
                                    <div class="col-6 col-12-mobile">
                                        <h3>
                                            <video width="500" height="400" controls><source src="images/boundingbox.mp4" type="video/mp4"></video>
                                        </h3>
                                    </div>
                                    <div class="col-6 col-12-mobile">
                                        <!-- <h3> -->
                                        <span class="vid fit"><video width="500" height="400" controls><source src="images/birdeye.mp4" type="video/mp4"></video></span>
                                        <!-- </h3> -->
                                    </div>
                            </div>
                            </article>
                            <br>
                        </div>
                        <div class = 'inside'>
                            <p>
                                <h5>
                                    <span style="color:rgb(0, 0, 0)">
                                        The number of fatal injuries on active construction sites has risen by nearly 90 percent in the last three years and our company 
                                        is not immune. The four most common workplace hazards are falls, electrocutions, struck by and caught by accidents that constitute 
                                        over 60 percent of such injuries. This project provides a solution that aims to improve worker awareness and company profits by 
                                        reliably notifying workers of their proximity to potential hazards and active machinery. For our project we would like to develop 
                                        a system that combines image processing and point-cloud based computer vision methods in order to track the movement of workers 
                                        around the construction site and warn them of entering potentially dangerous regions. We would target the most common construction 
                                        site hazards, namely: workers falling and being struck by objects. With this technology, our company will be able to easily identify 
                                        the hazardous areas on our construction sites and prevent some of the most fatal accidents that we see every year.
                                    <br/>
                                    <br/>
                                        For the design of the project, Our method is composed of 5 main steps. The first is to preprocess our worksite by selecting four fixed 
                                        points in the cameras field of view. This allows us account for the unique perspective of our camera and generate the respective 
                                        transformation matrix. Next, we read our video stream, and divide it into individual frames that You only look once (YOLO) can process. 
                                        Applying YOLO allows us to identify workers in each image, and using the outputted bounding box, we can map worker positions using our 
                                        previously defined transformation. Finally, we generate a map of worker positions for each frame and stitch that back together to form 
                                        an output video.  
                                    <br/>
                                    <br/>
                                        Given a video stream of our worksite, we need a way to map worker positions in the image, to worker positions in space. To do this we 
                                        rely on the fact that the camera’s position on the construction site is fixed and given 4 known positions we can generate a transformation 
                                        that maps pixel values to world coordinate values. This works because we assume all of the workers are on the same plane, implying that 
                                        their height is the same all times. So as you can see above, x, y are world coordinates and u and v are pixel coordinates. 
                                    <br/>
                                    <br/>
                                        After that we run YOLO on each of our frames, were given the pixels value for the center of the bounding box, and its dimensions. By 
                                        averaging the bottom of our bounding box, we can find a pixel representation of each worker’s position in each frame. We transform those 
                                        pixel values into world coordinates, using the matrix we found earlier. To generate our output video, we scale our world coordinate 
                                        positions by the size our output frame and boundary. We then stitch together each frame to create an animation. With our predefined 
                                        areas, we can accurately classify workers in danger areas.
                                    <br/>
                                    <br/>
                                        The project was able to successfully	track the location of the workers and plot their location on the bird-eyes view. We were able 
                                        to track multiple bodies simultaneously and track their locations accurately. This was achieved with the use of just one camera.
                                    </span>
                                </h5>
                            </p>
                        </div>
                    </div>

                </div>
            </section>

             <!--Buggy-->

             <section id="buggy" class="three">
                <div class="container">

                    <header>
                        <h2><span style="color:rgb(0, 0, 0)">Path planning and control strategies for an autonomous buggy</span></h2>
                    </header>
                    <div class="col-4 col-12-mobile">
                        <div class="inner">
                            <article class="item">
                                <div class="row">
                                    <div class="col-6 col-12-mobile">
                                        <h3><span class="image center"><img src="images/bicycle_model.png" width="200" height="300" /> </span></h3>
                                    </div>
                                    <div class="col-6 col-12-mobile">
                                        <h3><span class="image center"><img src="images/webots.png" width="200" height="300" /> </span></h3>
                                    </div>
                            </div>
                            </article>
                            <br>
                        </div>
                        <u1 class = 'inside'>
                            <h5>
                                <span style="color:rgb(0, 0, 0)">
                                    I created a simulation of an autonomous buggy going around the track (CMU's Buggy Track) in the most opimal path possible, with the use of a lateral and longitudinal controller.
                                    <br/>
                                    <br/>
                                    The simulation was done on Webots with the help of a tractor to indicate the buggy that is moving.
                                    <br/>
                                    <br/>
                                    The controller was designed based on the bicycle model for the study of vehicle dynamics. 
                                    <br/>
                                    <br/>
                                    The longitudinal controller is based GPS coordinates of the track and the 
                                    acceleration is calculated based on the closest node. 
                                    <br/>
                                    The lateral controller on the other hand went through 5 different iterations: 
                                    <ol type="1">
                                        <li>PID Controller</li>
                                        <li>State Feedback Controller</li>
                                        <li>LQR Controller</li>
                                        <li>MPC Controller</li>
                                        <li>EKF SLAM</li>
                                    </ol>
                                    
                                  
                                    With the use of these controllers the simulation was able to complete the track in less than 120 seconds and with less than 3 meters of deviation for the optimal path 
                                    of the track.
                                    <h3><span class="image center"><img src="images/MPC.png" width="300" height="400" /> </span></h3>
                                </span>
                            </h5>
                        </u1>
                    </div>
                    

                </div>
            </section>
        </div>    